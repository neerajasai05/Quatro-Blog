{
  "hash": "eadac0df05b7d906a30c5aa55b5e51f8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Building a Model Using Linear Regression for Car Price Prediction and Data Analysis\"\nauthor: \"Neeraja Sai Magisetti\"\ndate: \"2024-07-29\"\ncategories: [code, analysis]\nformat:       \n   html:\n      code-fold: true\njupyter: python3\nimage: car.png\n\n---\n\n\n## Problem Statement\nThe dataset consists of various attributes related to different car models, such as their specifications, performance metrics, and price. Goal is to analyze and model this data to understand the factors that influence car prices and to predict the price of a car based on its features.\n\nTaken a CSV file containing accurate historical data, which includes features and their actual prices. Task is to use this data to build a model that can predict the prices of cars that are not part of this dataset. The goal is to develop a reliable predictive model that can estimate the selling price of any car based on its features.\n\n::: {#4d3c3ff3 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\ndata = pd.read_csv('imports-85.data', delimiter=',', engine='python' )\nprint(data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   class normalized-losses         make fuel-type aspiration num-of-doors  \\\n0      3                 ?  alfa-romero       gas        std          two   \n1      3                 ?  alfa-romero       gas        std          two   \n2      1                 ?  alfa-romero       gas        std          two   \n3      2               164         audi       gas        std         four   \n4      2               164         audi       gas        std         four   \n\n    body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n0  convertible          rwd           front        88.6  ...          130   \n1  convertible          rwd           front        88.6  ...          130   \n2    hatchback          rwd           front        94.5  ...          152   \n3        sedan          fwd           front        99.8  ...          109   \n4        sedan          4wd           front        99.4  ...          136   \n\n   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n0         mpfi  3.47    2.68               9.0        111      5000       21   \n1         mpfi  3.47    2.68               9.0        111      5000       21   \n2         mpfi  2.68    3.47               9.0        154      5000       19   \n3         mpfi  3.19    3.40              10.0        102      5500       24   \n4         mpfi  3.19    3.40               8.0        115      5500       18   \n\n  highway-mpg  price  \n0          27  13495  \n1          27  16500  \n2          26  16500  \n3          30  13950  \n4          22  17450  \n\n[5 rows x 26 columns]\n```\n:::\n:::\n\n\n## Import Libraries\n\n::: {#8dbb86a2 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport seaborn as sns\nimport statsmodels.api as sm\n```\n:::\n\n\n![Libraries](libraries.png)\n\n\n## Analysis and Visualization\n\nIn order to understand the data that’s available, we must perform data analysis by visualizing the distribution of values in each feature, and the relationships between  price and other features. \n\n::: {#9ea66a8d .cell execution_count=3}\n``` {.python .cell-code}\nprint(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     class normalized-losses         make fuel-type aspiration num-of-doors  \\\n0        3                 ?  alfa-romero       gas        std          two   \n1        3                 ?  alfa-romero       gas        std          two   \n2        1                 ?  alfa-romero       gas        std          two   \n3        2               164         audi       gas        std         four   \n4        2               164         audi       gas        std         four   \n..     ...               ...          ...       ...        ...          ...   \n200     -1                95        volvo       gas        std         four   \n201     -1                95        volvo       gas      turbo         four   \n202     -1                95        volvo       gas        std         four   \n203     -1                95        volvo    diesel      turbo         four   \n204     -1                95        volvo       gas      turbo         four   \n\n      body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n0    convertible          rwd           front        88.6  ...          130   \n1    convertible          rwd           front        88.6  ...          130   \n2      hatchback          rwd           front        94.5  ...          152   \n3          sedan          fwd           front        99.8  ...          109   \n4          sedan          4wd           front        99.4  ...          136   \n..           ...          ...             ...         ...  ...          ...   \n200        sedan          rwd           front       109.1  ...          141   \n201        sedan          rwd           front       109.1  ...          141   \n202        sedan          rwd           front       109.1  ...          173   \n203        sedan          rwd           front       109.1  ...          145   \n204        sedan          rwd           front       109.1  ...          141   \n\n     fuel-system  bore  stroke compression-ratio horsepower  peak-rpm  \\\n0           mpfi  3.47    2.68               9.0        111      5000   \n1           mpfi  3.47    2.68               9.0        111      5000   \n2           mpfi  2.68    3.47               9.0        154      5000   \n3           mpfi  3.19    3.40              10.0        102      5500   \n4           mpfi  3.19    3.40               8.0        115      5500   \n..           ...   ...     ...               ...        ...       ...   \n200         mpfi  3.78    3.15               9.5        114      5400   \n201         mpfi  3.78    3.15               8.7        160      5300   \n202         mpfi  3.58    2.87               8.8        134      5500   \n203          idi  3.01    3.40              23.0        106      4800   \n204         mpfi  3.78    3.15               9.5        114      5400   \n\n    city-mpg highway-mpg  price  \n0         21          27  13495  \n1         21          27  16500  \n2         19          26  16500  \n3         24          30  13950  \n4         18          22  17450  \n..       ...         ...    ...  \n200       23          28  16845  \n201       19          25  19045  \n202       18          23  21485  \n203       26          27  22470  \n204       19          25  22625  \n\n[205 rows x 26 columns]\n```\n:::\n:::\n\n\nThe dataset contains 205 rows and 26 columns. Each row in the dataset contains information about one car. The task is to find a way to estimate the value in the “Price” column using the values in the other columns. If we can do this estimation for historical data, then we should be able to estimate price for new cars that are not in this data too, simply by providing information like class, normalized-losses, make, fuel-type, aspiration,num-of-doors, body-style, drive-wheels, engine-location, wheel-base, length, width,height,curb-weight, engine-type, num-of-cylinders, engine-size, fuel-system, bore,stroke,compression-ratio, horsepower, peak-rpm, city-mpg, highway-mpg.\n\n## Data Cleaning and Preprocessing:\n1. Handle missing values in columns such as normalized-losses and price.<br>\n2. Convert categorical data into numerical formats.\n\n::: {#6c1b8211 .cell execution_count=4}\n``` {.python .cell-code}\n# Handle missing data\nimport pandas as pd\ndata = pd.read_csv('imports-85.data', delimiter=',')\ndata.replace(\"?\",'', inplace=True)\n#print(data)\nfeature_columns = ['horsepower','bore','stroke','normalized-losses', 'price', 'peak-rpm']\n# Convert selected columns to numeric (if they aren't already)\nfor col in feature_columns:\n        data[col] = pd.to_numeric(data[col], errors='coerce')\n#print(data)\n```\n:::\n\n\nIn the dataset, some columns such as **price** and **horsepower** contain **\"?\"**.<br> Because of this, the columns are considered as objects, even though they contain numeric values. To overcome this issue, we should replace **?** with an **empty string**, and then convert the object columns to numeric using the **pd.to_numeric** function.<br>\n\n### Let’s check the data type of each column\n\n::: {#c417e17c .cell execution_count=5}\n``` {.python .cell-code}\ndata.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 205 entries, 0 to 204\nData columns (total 26 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   class              205 non-null    int64  \n 1   normalized-losses  164 non-null    float64\n 2   make               205 non-null    object \n 3   fuel-type          205 non-null    object \n 4   aspiration         205 non-null    object \n 5   num-of-doors       205 non-null    object \n 6   body-style         205 non-null    object \n 7   drive-wheels       205 non-null    object \n 8   engine-location    205 non-null    object \n 9   wheel-base         205 non-null    float64\n 10  length             205 non-null    float64\n 11  width              205 non-null    float64\n 12  height             205 non-null    float64\n 13  curb-weight        205 non-null    int64  \n 14  engine-type        205 non-null    object \n 15  num-of-cylinders   205 non-null    object \n 16  engine-size        205 non-null    int64  \n 17  fuel-system        205 non-null    object \n 18  bore               201 non-null    float64\n 19  stroke             201 non-null    float64\n 20  compression-ratio  205 non-null    float64\n 21  horsepower         203 non-null    float64\n 22  peak-rpm           203 non-null    float64\n 23  city-mpg           205 non-null    int64  \n 24  highway-mpg        205 non-null    int64  \n 25  price              201 non-null    float64\ndtypes: float64(11), int64(5), object(10)\nmemory usage: 41.8+ KB\n```\n:::\n:::\n\n\nWe could see that class, normalized-losses, wheel-base, length, width, height, curb-weight, engine-size, bore,stroke, compression-ratio, horsepower, peak-rpm, city-mpg, highway-mpg,   price are **numeric** whereas  make, fuel-type, aspiration,num-of-doors, body-style, drive-wheels, engine-location, engine-type, num-of-cylinders, fuel-system are **objects**( string) possibly categorical columns.\n\n### Explore some statistics for the numerical columns:\n\n::: {#e0cd1259 .cell execution_count=6}\n``` {.python .cell-code}\ndata.describe()\n\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>normalized-losses</th>\n      <th>wheel-base</th>\n      <th>length</th>\n      <th>width</th>\n      <th>height</th>\n      <th>curb-weight</th>\n      <th>engine-size</th>\n      <th>bore</th>\n      <th>stroke</th>\n      <th>compression-ratio</th>\n      <th>horsepower</th>\n      <th>peak-rpm</th>\n      <th>city-mpg</th>\n      <th>highway-mpg</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>205.000000</td>\n      <td>164.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>205.000000</td>\n      <td>203.000000</td>\n      <td>203.000000</td>\n      <td>205.000000</td>\n      <td>205.000000</td>\n      <td>201.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.834146</td>\n      <td>122.000000</td>\n      <td>98.756585</td>\n      <td>174.049268</td>\n      <td>65.907805</td>\n      <td>53.724878</td>\n      <td>2555.565854</td>\n      <td>126.907317</td>\n      <td>3.329751</td>\n      <td>3.255423</td>\n      <td>10.142537</td>\n      <td>104.256158</td>\n      <td>5125.369458</td>\n      <td>25.219512</td>\n      <td>30.751220</td>\n      <td>13207.129353</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.245307</td>\n      <td>35.442168</td>\n      <td>6.021776</td>\n      <td>12.337289</td>\n      <td>2.145204</td>\n      <td>2.443522</td>\n      <td>520.680204</td>\n      <td>41.642693</td>\n      <td>0.273539</td>\n      <td>0.316717</td>\n      <td>3.972040</td>\n      <td>39.714369</td>\n      <td>479.334560</td>\n      <td>6.542142</td>\n      <td>6.886443</td>\n      <td>7947.066342</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.000000</td>\n      <td>65.000000</td>\n      <td>86.600000</td>\n      <td>141.100000</td>\n      <td>60.300000</td>\n      <td>47.800000</td>\n      <td>1488.000000</td>\n      <td>61.000000</td>\n      <td>2.540000</td>\n      <td>2.070000</td>\n      <td>7.000000</td>\n      <td>48.000000</td>\n      <td>4150.000000</td>\n      <td>13.000000</td>\n      <td>16.000000</td>\n      <td>5118.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>94.000000</td>\n      <td>94.500000</td>\n      <td>166.300000</td>\n      <td>64.100000</td>\n      <td>52.000000</td>\n      <td>2145.000000</td>\n      <td>97.000000</td>\n      <td>3.150000</td>\n      <td>3.110000</td>\n      <td>8.600000</td>\n      <td>70.000000</td>\n      <td>4800.000000</td>\n      <td>19.000000</td>\n      <td>25.000000</td>\n      <td>7775.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>115.000000</td>\n      <td>97.000000</td>\n      <td>173.200000</td>\n      <td>65.500000</td>\n      <td>54.100000</td>\n      <td>2414.000000</td>\n      <td>120.000000</td>\n      <td>3.310000</td>\n      <td>3.290000</td>\n      <td>9.000000</td>\n      <td>95.000000</td>\n      <td>5200.000000</td>\n      <td>24.000000</td>\n      <td>30.000000</td>\n      <td>10295.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>150.000000</td>\n      <td>102.400000</td>\n      <td>183.100000</td>\n      <td>66.900000</td>\n      <td>55.500000</td>\n      <td>2935.000000</td>\n      <td>141.000000</td>\n      <td>3.590000</td>\n      <td>3.410000</td>\n      <td>9.400000</td>\n      <td>116.000000</td>\n      <td>5500.000000</td>\n      <td>30.000000</td>\n      <td>34.000000</td>\n      <td>16500.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.000000</td>\n      <td>256.000000</td>\n      <td>120.900000</td>\n      <td>208.100000</td>\n      <td>72.300000</td>\n      <td>59.800000</td>\n      <td>4066.000000</td>\n      <td>326.000000</td>\n      <td>3.940000</td>\n      <td>4.170000</td>\n      <td>23.000000</td>\n      <td>288.000000</td>\n      <td>6600.000000</td>\n      <td>49.000000</td>\n      <td>54.000000</td>\n      <td>45400.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Correlation\n\nThe relationship between two numerical features such as price and hoursepower etc. can be numerically expressed using a measure called correlation coefficient, which can be computed using the .corr method from the pandas' library.\n\n**For example to compute the correlation coefficient of price and hoursepower:**\n\n![correlation_coefficient](correlation_coefficient.png)<br>\n\nThis is for price and hoursepower.\n\n**Let's see correlation_coefficient for each numeric feature with price.**\n\n::: {#76c086a7 .cell execution_count=7}\n``` {.python .cell-code}\ncorrelation_coefficient_columns = ['normalized-losses','wheel-base','length','width','height','curb-weight','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']\nfor col in correlation_coefficient_columns:\n    correlation_coefficient = data['price'].corr(data[col])\n    print(f\"Correlation between price and {col}: {correlation_coefficient}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorrelation between price and normalized-losses: 0.20325417074184238\nCorrelation between price and wheel-base: 0.5846418222655085\nCorrelation between price and length: 0.6906283804483649\nCorrelation between price and width: 0.7512653440522669\nCorrelation between price and height: 0.13548630756805982\nCorrelation between price and curb-weight: 0.8344145257702834\nCorrelation between price and engine-size: 0.8723351674455196\nCorrelation between price and bore: 0.5434358664188549\nCorrelation between price and stroke: 0.0823098273897049\nCorrelation between price and compression-ratio: 0.07110732668194138\nCorrelation between price and horsepower: 0.8105330821322059\nCorrelation between price and peak-rpm: -0.10164886620219901\nCorrelation between price and city-mpg: -0.686571006784468\nCorrelation between price and highway-mpg: -0.704692265058953\n```\n:::\n:::\n\n\nWe could observe from the values above, that there’s a high correlation between **price** and **engine-size** but less correlation between **price** and **highway-mpg**.\n\nWe can use the **.corr()** method to show the correlation coefficients between all pairs of numerical columns.\n\n::: {#d76c0dce .cell execution_count=8}\n``` {.python .cell-code}\ndata.corr(method='pearson',numeric_only=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>normalized-losses</th>\n      <th>wheel-base</th>\n      <th>length</th>\n      <th>width</th>\n      <th>height</th>\n      <th>curb-weight</th>\n      <th>engine-size</th>\n      <th>bore</th>\n      <th>stroke</th>\n      <th>compression-ratio</th>\n      <th>horsepower</th>\n      <th>peak-rpm</th>\n      <th>city-mpg</th>\n      <th>highway-mpg</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>class</th>\n      <td>1.000000</td>\n      <td>0.528667</td>\n      <td>-0.531954</td>\n      <td>-0.357612</td>\n      <td>-0.232919</td>\n      <td>-0.541038</td>\n      <td>-0.227691</td>\n      <td>-0.105790</td>\n      <td>-0.134205</td>\n      <td>-0.008965</td>\n      <td>-0.178515</td>\n      <td>0.071622</td>\n      <td>0.274573</td>\n      <td>-0.035823</td>\n      <td>0.034606</td>\n      <td>-0.082391</td>\n    </tr>\n    <tr>\n      <th>normalized-losses</th>\n      <td>0.528667</td>\n      <td>1.000000</td>\n      <td>-0.074362</td>\n      <td>0.023220</td>\n      <td>0.105073</td>\n      <td>-0.432335</td>\n      <td>0.119893</td>\n      <td>0.167365</td>\n      <td>-0.036167</td>\n      <td>0.065627</td>\n      <td>-0.132654</td>\n      <td>0.295772</td>\n      <td>0.264597</td>\n      <td>-0.258502</td>\n      <td>-0.210768</td>\n      <td>0.203254</td>\n    </tr>\n    <tr>\n      <th>wheel-base</th>\n      <td>-0.531954</td>\n      <td>-0.074362</td>\n      <td>1.000000</td>\n      <td>0.874587</td>\n      <td>0.795144</td>\n      <td>0.589435</td>\n      <td>0.776386</td>\n      <td>0.569329</td>\n      <td>0.490378</td>\n      <td>0.161477</td>\n      <td>0.249786</td>\n      <td>0.352297</td>\n      <td>-0.361052</td>\n      <td>-0.470414</td>\n      <td>-0.544082</td>\n      <td>0.584642</td>\n    </tr>\n    <tr>\n      <th>length</th>\n      <td>-0.357612</td>\n      <td>0.023220</td>\n      <td>0.874587</td>\n      <td>1.000000</td>\n      <td>0.841118</td>\n      <td>0.491029</td>\n      <td>0.877728</td>\n      <td>0.683360</td>\n      <td>0.607480</td>\n      <td>0.129739</td>\n      <td>0.158414</td>\n      <td>0.555003</td>\n      <td>-0.287325</td>\n      <td>-0.670909</td>\n      <td>-0.704662</td>\n      <td>0.690628</td>\n    </tr>\n    <tr>\n      <th>width</th>\n      <td>-0.232919</td>\n      <td>0.105073</td>\n      <td>0.795144</td>\n      <td>0.841118</td>\n      <td>1.000000</td>\n      <td>0.279210</td>\n      <td>0.867032</td>\n      <td>0.735433</td>\n      <td>0.559204</td>\n      <td>0.182956</td>\n      <td>0.181129</td>\n      <td>0.642482</td>\n      <td>-0.219957</td>\n      <td>-0.642704</td>\n      <td>-0.677218</td>\n      <td>0.751265</td>\n    </tr>\n    <tr>\n      <th>height</th>\n      <td>-0.541038</td>\n      <td>-0.432335</td>\n      <td>0.589435</td>\n      <td>0.491029</td>\n      <td>0.279210</td>\n      <td>1.000000</td>\n      <td>0.295572</td>\n      <td>0.067149</td>\n      <td>0.176195</td>\n      <td>-0.056999</td>\n      <td>0.261214</td>\n      <td>-0.110711</td>\n      <td>-0.322272</td>\n      <td>-0.048640</td>\n      <td>-0.107358</td>\n      <td>0.135486</td>\n    </tr>\n    <tr>\n      <th>curb-weight</th>\n      <td>-0.227691</td>\n      <td>0.119893</td>\n      <td>0.776386</td>\n      <td>0.877728</td>\n      <td>0.867032</td>\n      <td>0.295572</td>\n      <td>1.000000</td>\n      <td>0.850594</td>\n      <td>0.649045</td>\n      <td>0.168929</td>\n      <td>0.151362</td>\n      <td>0.751034</td>\n      <td>-0.266306</td>\n      <td>-0.757414</td>\n      <td>-0.797465</td>\n      <td>0.834415</td>\n    </tr>\n    <tr>\n      <th>engine-size</th>\n      <td>-0.105790</td>\n      <td>0.167365</td>\n      <td>0.569329</td>\n      <td>0.683360</td>\n      <td>0.735433</td>\n      <td>0.067149</td>\n      <td>0.850594</td>\n      <td>1.000000</td>\n      <td>0.594090</td>\n      <td>0.206675</td>\n      <td>0.028971</td>\n      <td>0.810773</td>\n      <td>-0.244618</td>\n      <td>-0.653658</td>\n      <td>-0.677470</td>\n      <td>0.872335</td>\n    </tr>\n    <tr>\n      <th>bore</th>\n      <td>-0.134205</td>\n      <td>-0.036167</td>\n      <td>0.490378</td>\n      <td>0.607480</td>\n      <td>0.559204</td>\n      <td>0.176195</td>\n      <td>0.649045</td>\n      <td>0.594090</td>\n      <td>1.000000</td>\n      <td>-0.055909</td>\n      <td>0.005203</td>\n      <td>0.577273</td>\n      <td>-0.264269</td>\n      <td>-0.594584</td>\n      <td>-0.594572</td>\n      <td>0.543436</td>\n    </tr>\n    <tr>\n      <th>stroke</th>\n      <td>-0.008965</td>\n      <td>0.065627</td>\n      <td>0.161477</td>\n      <td>0.129739</td>\n      <td>0.182956</td>\n      <td>-0.056999</td>\n      <td>0.168929</td>\n      <td>0.206675</td>\n      <td>-0.055909</td>\n      <td>1.000000</td>\n      <td>0.186170</td>\n      <td>0.090254</td>\n      <td>-0.071493</td>\n      <td>-0.042906</td>\n      <td>-0.044528</td>\n      <td>0.082310</td>\n    </tr>\n    <tr>\n      <th>compression-ratio</th>\n      <td>-0.178515</td>\n      <td>-0.132654</td>\n      <td>0.249786</td>\n      <td>0.158414</td>\n      <td>0.181129</td>\n      <td>0.261214</td>\n      <td>0.151362</td>\n      <td>0.028971</td>\n      <td>0.005203</td>\n      <td>0.186170</td>\n      <td>1.000000</td>\n      <td>-0.205874</td>\n      <td>-0.436221</td>\n      <td>0.324701</td>\n      <td>0.265201</td>\n      <td>0.071107</td>\n    </tr>\n    <tr>\n      <th>horsepower</th>\n      <td>0.071622</td>\n      <td>0.295772</td>\n      <td>0.352297</td>\n      <td>0.555003</td>\n      <td>0.642482</td>\n      <td>-0.110711</td>\n      <td>0.751034</td>\n      <td>0.810773</td>\n      <td>0.577273</td>\n      <td>0.090254</td>\n      <td>-0.205874</td>\n      <td>1.000000</td>\n      <td>0.130971</td>\n      <td>-0.803620</td>\n      <td>-0.770908</td>\n      <td>0.810533</td>\n    </tr>\n    <tr>\n      <th>peak-rpm</th>\n      <td>0.274573</td>\n      <td>0.264597</td>\n      <td>-0.361052</td>\n      <td>-0.287325</td>\n      <td>-0.219957</td>\n      <td>-0.322272</td>\n      <td>-0.266306</td>\n      <td>-0.244618</td>\n      <td>-0.264269</td>\n      <td>-0.071493</td>\n      <td>-0.436221</td>\n      <td>0.130971</td>\n      <td>1.000000</td>\n      <td>-0.113788</td>\n      <td>-0.054257</td>\n      <td>-0.101649</td>\n    </tr>\n    <tr>\n      <th>city-mpg</th>\n      <td>-0.035823</td>\n      <td>-0.258502</td>\n      <td>-0.470414</td>\n      <td>-0.670909</td>\n      <td>-0.642704</td>\n      <td>-0.048640</td>\n      <td>-0.757414</td>\n      <td>-0.653658</td>\n      <td>-0.594584</td>\n      <td>-0.042906</td>\n      <td>0.324701</td>\n      <td>-0.803620</td>\n      <td>-0.113788</td>\n      <td>1.000000</td>\n      <td>0.971337</td>\n      <td>-0.686571</td>\n    </tr>\n    <tr>\n      <th>highway-mpg</th>\n      <td>0.034606</td>\n      <td>-0.210768</td>\n      <td>-0.544082</td>\n      <td>-0.704662</td>\n      <td>-0.677218</td>\n      <td>-0.107358</td>\n      <td>-0.797465</td>\n      <td>-0.677470</td>\n      <td>-0.594572</td>\n      <td>-0.044528</td>\n      <td>0.265201</td>\n      <td>-0.770908</td>\n      <td>-0.054257</td>\n      <td>0.971337</td>\n      <td>1.000000</td>\n      <td>-0.704692</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>-0.082391</td>\n      <td>0.203254</td>\n      <td>0.584642</td>\n      <td>0.690628</td>\n      <td>0.751265</td>\n      <td>0.135486</td>\n      <td>0.834415</td>\n      <td>0.872335</td>\n      <td>0.543436</td>\n      <td>0.082310</td>\n      <td>0.071107</td>\n      <td>0.810533</td>\n      <td>-0.101649</td>\n      <td>-0.686571</td>\n      <td>-0.704692</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Visualization of above table using a heatmap.\n\n::: {#41fb9bcc .cell execution_count=9}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 8))\nsns.heatmap(data.corr(method='pearson',numeric_only=True), cmap='Reds', annot=True)\n#print(data)\nplt.title('Correlation Matrix')\n\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nText(0.5, 1.0, 'Correlation Matrix')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](linear_files/figure-html/cell-10-output-2.png){width=987 height=760}\n:::\n:::\n\n\n<br>\n\nIn the correlation matrix, we observe that features like **horsepower, engine-size, curb-weight, and width** have high correlations with the price, close to **+1**, indicating a strong positive linear relationship. On the other hand, **length** is highly correlated with **wheel-base**, suggesting that including both in the model might lead to redundant information.\n\nIf **length and wheel-base** provide overlapping information, adding both to the model may not improve its predictive power. Instead, the model might perform better with a combination of features that provide complementary information. For instance, **wheel-base and bore** might together explain different aspects of price variation that length does not capture.\n\nTherefore, the features **horsepower, engine-size, curb-weight, width, wheel-base, and bore** are chosen to build a more effective linear regression model.\n\n## Linear Regression using a Single Feature\n\n::: {#471c5f2b .cell execution_count=10}\n``` {.python .cell-code}\ndata = data.assign(price=data['price'].fillna(data['price'].mean()))\ndata = data.assign(horsepower=data['horsepower'].fillna(data['horsepower'].mean()))\ndata = data.assign(bore=data['bore'].fillna(data['bore'].mean()))\n\n# Independent variables\nX = data[['horsepower', 'engine-size','curb-weight', 'width', 'wheel-base','bore']] \n#Dependent variable\ny = data['price']           \n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\n![Train_and_Test_data](Train_and_Test_data.png)<br>\n\n**Here we can see how train and test data splited** <br>\n\n## Training the model\n\n![Traing the Model](traing_model.png)\n\n::: {#03b9873d .cell execution_count=11}\n``` {.python .cell-code}\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n# Make predictions on the training set\ny_train_pred = model.predict(X_train)\n\n# Make predictions on the testing set\ny_test_pred = model.predict(X_val)\n\ny_test_pred_series = pd.Series(y_test_pred, index=y_test.index)\n\n#print(y_test)\n#print(y_test_pred_series)\n```\n:::\n\n\n## Evaluation\n\n::: {#ccd5e3c1 .cell execution_count=12}\n``` {.python .cell-code}\n# Calculate Mean Squared Error\ntrain_mse = mean_squared_error(y_train, y_train_pred)\ntest_mse = mean_squared_error(y_test, y_test_pred)\n\n# Calculate Mean Absolute Error\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\n\n# Calculate R² Score\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\n\nprint(f\"Training MSE: {train_mse}\")\nprint(f\"Testing MSE: {test_mse}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining MSE: 13294997.434275284\nTesting MSE: 15211446.60565294\n```\n:::\n:::\n\n\n::: {#22ef9a06 .cell execution_count=13}\n``` {.python .cell-code}\nprint(f\"Training MAE: {train_mae}\")\nprint(f\"Testing MAE: {test_mae}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining MAE: 2422.7614602035196\nTesting MAE: 2719.9431238534353\n```\n:::\n:::\n\n\n::: {#dec51d45 .cell execution_count=14}\n``` {.python .cell-code}\nprint(f\"Training R²: {train_r2}\")\nprint(f\"Testing R²: {test_r2}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining R²: 0.7687942097124424\nTesting R²: 0.8049116113376993\n```\n:::\n:::\n\n\n## Ploting\n\n::: {#995be35c .cell execution_count=15}\n``` {.python .cell-code}\n# Plotting\n\nplt.figure(figsize=(8,6))\n# Plot training data and regression line\nplt.scatter(y_train_pred, y_train,  color='blue', edgecolor='w', alpha=0.6, label='Predicted Training Data')\nplt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--', label='Perfect Fit Line')\n\n# Add title and labels\nplt.title('Training Data vs. Predictions')\nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(8,6))\n# Plot training data and regression line\nplt.scatter(y_test_pred, y_test,  color='blue', edgecolor='w', alpha=0.6, label='Predicted Test Data')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Perfect Fit Line')\n# Add title and labels\nplt.title('Test Data vs. Predictions')\nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](linear_files/figure-html/cell-16-output-1.png){width=684 height=523}\n:::\n\n::: {.cell-output .cell-output-display}\n![](linear_files/figure-html/cell-16-output-2.png){width=684 height=523}\n:::\n:::\n\n\n### Using the statsmodels library to find the coefficients, standard errors, t-statistics, and p-values\n\n::: {#ea3e1a42 .cell execution_count=16}\n``` {.python .cell-code}\nX = sm.add_constant(X)\n\n# Fit the model\nmodel = sm.OLS(y, X).fit()\n\n# Print the summary\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  price   R-squared:                       0.779\nModel:                            OLS   Adj. R-squared:                  0.772\nMethod:                 Least Squares   F-statistic:                     116.3\nDate:                Tue, 27 Aug 2024   Prob (F-statistic):           3.92e-62\nTime:                        13:58:25   Log-Likelihood:                -1974.7\nNo. Observations:                 205   AIC:                             3963.\nDf Residuals:                     198   BIC:                             3987.\nDf Model:                           6                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P>|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nconst       -2.489e+04   1.44e+04     -1.724      0.086   -5.34e+04    3581.183\nhorsepower     32.9611     13.982      2.357      0.019       5.389      60.534\nengine-size    97.3789     13.822      7.045      0.000      70.123     124.635\ncurb-weight     3.0629      1.579      1.939      0.054      -0.052       6.177\nwidth         175.5085    275.708      0.637      0.525    -368.192     719.209\nwheel-base     80.4906     93.642      0.860      0.391    -104.172     265.153\nbore        -1515.2777   1301.364     -1.164      0.246   -4081.591    1051.035\n==============================================================================\nOmnibus:                       31.978   Durbin-Watson:                   1.024\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              122.707\nSkew:                           0.511   Prob(JB):                     2.26e-27\nKurtosis:                       6.650   Cond. No.                     1.44e+05\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.44e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n```\n:::\n:::\n\n\n",
    "supporting": [
      "linear_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}